<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Artificial-Intelligence on Content</title><link>https://garthjacques.github.io/tags/artificial-intelligence/</link><description>Recent content in Artificial-Intelligence on Content</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Wed, 21 Jan 2026 00:00:00 +0000</lastBuildDate><atom:link href="https://garthjacques.github.io/tags/artificial-intelligence/index.xml" rel="self" type="application/rss+xml"/><item><title>A-MEM: Agentic Memory for LLM Agents</title><link>https://garthjacques.github.io/library/a-mem-agentic-memory-for-llm-agents/</link><pubDate>Wed, 21 Jan 2026 00:00:00 +0000</pubDate><guid>https://garthjacques.github.io/library/a-mem-agentic-memory-for-llm-agents/</guid><description>&lt;h2 id="a-mem-agentic-memory-for-llm-agents"&gt;A-MEM: Agentic Memory for LLM Agents&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Wujiang Xu, Zuzie Liang, Kai Mei, Hang Gao, Juntao Tan, Yongfeng Zhang&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Affiliations:&lt;/strong&gt; Rutgers University, AntGroup, Salesforce Research&lt;/p&gt;
&lt;h3 id="abstract"&gt;Abstract&lt;/h3&gt;
&lt;p&gt;While large language model (LLM) agents can effectively use external tools for complex real-world tasks, they require memory systems to leverage historical experiences. Current memory systems enable basic storage and retrieval but lack sophisticated memory organization, despite recent attempts to incorporate graph databases. Moreover, these systems&amp;rsquo; fixed operations and structures limit their adaptability across diverse tasks. To address this limitation, this paper proposes a novel agentic memory system for LLM agents that can dynamically organize memories in an agentic way.&lt;/p&gt;</description></item><item><title>AI Agents vs. Agentic AI: A Conceptual taxonomy, applications and challenges</title><link>https://garthjacques.github.io/library/ai-agents-vs-agentic-ai-a-conceptual-taxonomy-applications-and-challenges/</link><pubDate>Wed, 21 Jan 2026 00:00:00 +0000</pubDate><guid>https://garthjacques.github.io/library/ai-agents-vs-agentic-ai-a-conceptual-taxonomy-applications-and-challenges/</guid><description>&lt;h2 id="foundational-understanding-of-ai-agents"&gt;Foundational understanding of AI Agents&lt;/h2&gt;
&lt;p&gt;AI Agents can be defined as autonomous software entities engineered for goal-directed task execution within bounded digital environments. These agents are defined by their ability to perceive structured or unstructured inputs, to reason over contextual information, and to initiate actions toward achieving specific objectives, often acting as surrogates for human users or subsystems. Unlike conventional automation scripts, which follow deterministic workflows, AI Agents demonstrate reactive intelligence and some level of adaptability, allowing them to interpret dynamic inputs and reconfigure outputs accordingly. Their adoption has been reported across a wide range of application domains, including customer service automation, personal productivity assistance, organizational information retrieval, and decision support systems.&lt;/p&gt;</description></item><item><title>Trivial Trojans: How Minimal MCP Servers Enable Cross-Tool Exfiltration of Sensitive Data</title><link>https://garthjacques.github.io/library/trivial-trojans-how-minimal-mcp-servers-enable-cross-tool-exfiltration-of-sensitive-data/</link><pubDate>Wed, 21 Jan 2026 00:00:00 +0000</pubDate><guid>https://garthjacques.github.io/library/trivial-trojans-how-minimal-mcp-servers-enable-cross-tool-exfiltration-of-sensitive-data/</guid><description>&lt;h2 id="abstract"&gt;Abstract&lt;/h2&gt;
&lt;p&gt;The Model Context Protocol (MCP) represents a significant advancement in AI-tool integration, enabling seamless communication between AI agents and external services. However, this connectivity introduces novel attack vectors that remain largely unexplored. This paper demonstrates how unsophisticated threat actors, requiring only basic programming skills and free web tools, can exploit MCP&amp;rsquo;s trust model to exfiltrate sensitive financial data. We present a proof-of-concept attack where a malicious weather MCP server, disguised as benign functionality, discovers and exploits legitimate banking tools to steal user account balances. The attack chain requires no advanced technical knowledge, server infrastructure, or monetary investment. The findings reveal a critical security gap in the emerging MCP ecosystem: while individual servers may appear trustworthy, their combination creates unexpected cross-server attack surfaces. Unlike traditional cybersecurity threats that assume sophisticated adversaries, our research shows that the barrier to entry for MCP-based attacks is alarmingly low. A threat actor with undergraduate-level Python knowledge can craft convincing social engineering attacks that exploit the implicit trust relationships MCP establishes between AI agents and tool providers. This work contributes to the nascent field of MCP security by demonstrating that current MCP implementations allow trivial cross-server attacks and proposing both immediate mitigations and protocol improvements to secure this emerging ecosystem.&lt;/p&gt;</description></item></channel></rss>